{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08fdde88-20f3-4806-92f9-e78023f1f9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tomogram: /home/tfg/Desktop/Patricia/polnet/data/data_generated/all_v11/tomos/tomo_rec_6_snr1.04.mrc\n",
      "\tProcessing label: membrane\n",
      "\tProcessing label: mb_prot\n",
      "Processing tomogram: /home/tfg/Desktop/Patricia/polnet/data/data_generated/all_v11/tomos/tomo_rec_0_snr1.01.mrc\n",
      "\tProcessing label: membrane\n",
      "\tProcessing label: mb_prot\n",
      "Processing tomogram: /home/tfg/Desktop/Patricia/polnet/data/data_generated/all_v11/tomos/tomo_rec_2_snr1.9.mrc\n",
      "\tProcessing label: membrane\n",
      "\tProcessing label: mb_prot\n",
      "Processing tomogram: /home/tfg/Desktop/Patricia/polnet/data/data_generated/all_v11/tomos/tomo_rec_8_snr1.5.mrc\n",
      "\tProcessing label: membrane\n",
      "\tProcessing label: mb_prot\n",
      "Processing tomogram: /home/tfg/Desktop/Patricia/polnet/data/data_generated/all_v11/tomos/tomo_rec_7_snr1.78.mrc\n",
      "\tProcessing label: membrane\n",
      "\tProcessing label: mb_prot\n",
      "Processing tomogram: /home/tfg/Desktop/Patricia/polnet/data/data_generated/all_v11/tomos/tomo_rec_4_snr1.42.mrc\n",
      "\tProcessing label: membrane\n",
      "\tProcessing label: mb_prot\n",
      "Processing tomogram: /home/tfg/Desktop/Patricia/polnet/data/data_generated/all_v11/tomos/tomo_rec_9_snr1.0.mrc\n",
      "\tProcessing label: membrane\n",
      "\tProcessing label: mb_prot\n",
      "Processing tomogram: /home/tfg/Desktop/Patricia/polnet/data/data_generated/all_v11/tomos/tomo_rec_3_snr1.46.mrc\n",
      "\tProcessing label: membrane\n",
      "\tProcessing label: mb_prot\n",
      "Processing tomogram: /home/tfg/Desktop/Patricia/polnet/data/data_generated/all_v11/tomos/tomo_rec_1_snr1.31.mrc\n",
      "\tProcessing label: membrane\n",
      "\tProcessing label: mb_prot\n",
      "Processing tomogram: /home/tfg/Desktop/Patricia/polnet/data/data_generated/all_v11/tomos/tomo_rec_5_snr1.79.mrc\n",
      "\tProcessing label: membrane\n",
      "\tProcessing label: mb_prot\n",
      "Successfully terminated. (Mon Jun  2 10:05:56 2025)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import nrrd\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from polnet import lio\n",
    "\n",
    "ROOT_DIR = Path(\"~/Desktop/Patricia/polnet/data\")\n",
    "in_csv = ROOT_DIR / \"data_generated/all_v11/tomos_motif_list.csv\"\n",
    "out_dir = Path(os.getenv(\"nnUNet_raw\") or ROOT_DIR / \"data_prepared\")\n",
    "dataset_id = \"004\"\n",
    "dataset_suffix = \"SV\"\n",
    "\n",
    "fg_labels = {\n",
    "    \"membrane\": (1,),\n",
    "    \"mb_prot\": (2,3,4,5)\n",
    "}\n",
    "\n",
    "mb_prot_radius_vox = 120  # in Angstroms, later scaled by voxel size\n",
    "\n",
    "# Read metadata\n",
    "df = pd.read_csv(in_csv, delimiter=\"\\t\")\n",
    "tomos = set(df[\"Tomo3D\"].tolist())\n",
    "segs = {\n",
    "    tomo: os.path.join(os.path.dirname(tomo), f\"tomo_lbls_{os.path.basename(tomo).split('_')[2]}.mrc\")\n",
    "    for tomo in tomos\n",
    "}\n",
    "\n",
    "# Output folder structure\n",
    "out_dataset = out_dir / f\"Dataset{dataset_id}_{dataset_suffix}\"\n",
    "if os.path.exists(out_dataset):\n",
    "    shutil.rmtree(out_dataset)\n",
    "os.makedirs(out_dataset / \"imagesTr\")\n",
    "os.makedirs(out_dataset / \"labelsTr\")\n",
    "\n",
    "out_labels = {\"background\": 0}\n",
    "\n",
    "for tomo_id, tomo_in in enumerate(tomos):\n",
    "    print(f\"Processing tomogram: {tomo_in}\")\n",
    "    tomo = lio.load_mrc(tomo_in)\n",
    "    seg = lio.load_mrc(segs[tomo_in])\n",
    "    seg_post = np.zeros_like(seg, dtype=np.uint8)\n",
    "    v_sizes = lio.read_mrc_v_size(tomo_in)\n",
    "    v_size = float(v_sizes[0])  # assuming isotropic\n",
    "    v_size_i = 1.0 / v_size\n",
    "\n",
    "    tomo_df = df[df[\"Tomo3D\"] == tomo_in]\n",
    "\n",
    "    for i, key in enumerate(fg_labels.keys()):\n",
    "        print(f\"\\tProcessing label: {key}\")\n",
    "        lbl_value = i + 1\n",
    "        if key == \"mb_prot\":\n",
    "            feat_df = tomo_df[tomo_df[\"Label\"].isin(fg_labels[key])]\n",
    "            for _, row in feat_df.iterrows():\n",
    "                xi = int(round(row[\"X\"] * v_size_i))\n",
    "                yi = int(round(row[\"Y\"] * v_size_i))\n",
    "                zi = int(round(row[\"Z\"] * v_size_i))\n",
    "                ri = int(round(mb_prot_radius_vox * v_size_i))\n",
    "                x_min, x_max = max(xi - ri, 0), min(xi + ri + 1, tomo.shape[0])\n",
    "                y_min, y_max = max(yi - ri, 0), min(yi + ri + 1, tomo.shape[1])\n",
    "                z_min, z_max = max(zi - ri, 0), min(zi + ri + 1, tomo.shape[2])\n",
    "                for x in range(x_min, x_max):\n",
    "                    for y in range(y_min, y_max):\n",
    "                        for z in range(z_min, z_max):\n",
    "                            if (x - xi)**2 + (y - yi)**2 + (z - zi)**2 <= ri**2:\n",
    "                                seg_post[x, y, z] = lbl_value\n",
    "        else:\n",
    "            for lbl in fg_labels[key]:\n",
    "                seg_post[seg == lbl] = lbl_value\n",
    "\n",
    "        out_labels[key] = lbl_value\n",
    "\n",
    "    # Save NRRD\n",
    "    tomo_out_name = f\"tomo_{str(tomo_id).zfill(3)}\"\n",
    "    nrrd.write(str(out_dataset / f\"imagesTr/{tomo_out_name}_0000.nrrd\"), tomo)\n",
    "    nrrd.write(str(out_dataset / f\"labelsTr/{tomo_out_name}.nrrd\"), seg_post)\n",
    "\n",
    "# Dataset JSON\n",
    "dict_json = {\n",
    "    \"channel_names\": {\"0\": \"rescale_to_0_1\"},\n",
    "    \"labels\": out_labels,\n",
    "    \"numTraining\": 16,\n",
    "    \"file_ending\": \".nrrd\",\n",
    "}\n",
    "with open(out_dataset / \"dataset.json\", \"w\") as outfile:\n",
    "    json.dump(dict_json, outfile, indent=4)\n",
    "\n",
    "print(\"Successfully terminated. (\" + time.strftime(\"%c\") + \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edbdf65-59a4-494a-9960-52bc9d77d2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
